{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudo de caso - obtenção automática de dados da Wikipedia\n",
    "\n",
    "1. Abrir um artigo;\n",
    "2. Encontrar o primeiro link no artigo;\n",
    "3. Clicar no link;\n",
    "4. Armazenar o link na estrutura article_chain.\n",
    "5. Repetir o processo até chegarmos ao artigo de filosofia ou ficarmos presos em um ciclo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A sequência dos passos\n",
    "Nós determinamos que nosso programa será estruturado como um laço do tipo while. Anteriormente, também determinamos os passos que devem ser realizados dentro desse laço.\n",
    "\n",
    "1. Encontrar o primeiro link no HTML do artigo que está sendo analisado\n",
    "2. Baixar o HTML do artigo que está sendo analisado\n",
    "3. Adicionar o primeiro link deste artigo em article_chain\n",
    "4. Existe outro passo que nós não explicitamos anteriormente:\n",
    "\n",
    "Pausar por alguns segundos o nosso processo para não exaurir a Wikipedia com requisições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d6b7976f3150>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinue_crawl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_chain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m# realiza o download do HTML do último artigo em article_chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# encontra o primeiro link nesse HTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_chain' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def find_first_link(url):\n",
    "    # retorna o primeiro link como uma string, ou \"none\" se não houver nenhum link\n",
    "    # pega o HTML de \"url\", usando a biblioteca de requisições\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    # insere o HTML no Beautiful Soup\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    # encontra o primeiro link do artigo\n",
    "    # retorna o primeiro link como uma string, ou \"none\", se não houver link\n",
    "\n",
    "def continue_crawl(search_history, target_url, max_steps=25):\n",
    "    \"\"\"\n",
    "    A função continue_crawl deve retornar True ou False dependendo dessas regras:\n",
    "    1. Se o artigo mais recente em search_history é o artigo final (target_url), então, a busca deve parar e a função deve retornar False\n",
    "    2. se a lista possui mais de 25 URLs, a função deve retornar False\n",
    "    3. Se a lista possui um ciclo interno, a função deve retornar False\n",
    "    4. Em último caso, a busca deve continuar e a função deve retornar True\n",
    "    \"\"\"\n",
    "    if search_history[-1] == target_url:\n",
    "        print(\"We've found the target article!\")\n",
    "        return False\n",
    "    elif len(search_history) > max_steps:\n",
    "        print(\"The search has gone on suspiciously: aborting search\")\n",
    "        return False\n",
    "    elif search_history[-1] == search_history[:-1]:\n",
    "        print(\"We've arrived at an article we've already seen\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "while(continue_crawl(article_chain, target_url)):\n",
    "    # realiza o download do HTML do último artigo em article_chain\n",
    "    # encontra o primeiro link nesse HTML\n",
    "    first_link = find_first_link(article_chain[-1])\n",
    "    # adiciona o primeiro link em article_chain\n",
    "    article_chain.append(first_link)\n",
    "    # aguarda 2 segundos antes de continuar\n",
    "    time.sleep(2)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
